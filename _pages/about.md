---
layout: about
title: me
permalink: /
subtitle: >
    Research Scientist at Scale AI
    <!-- <p class="motto"> <em> motto </em> </p> -->
profile:
  align: center
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p> akyurekafra [at] gmail [dot] com
    <p> San Francisco Bay Area </p>
news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---
I am a Research Scientist at Scale AI, working on LLM post-training and evaluation. I received my PhD in Computer Science from Boston University in May 2025.

My research focuses on self-learning and enhancing language model interactions to be more akin to human-like communication. Having inspired by how humans modify their knowledge and beliefs through feedback received in natural language or garnered from the environment, my specific interest lies in how such feedback, expressed in natural language, can *guide a language modelâ€™s outputs to align with facts, requirements, natural phenomena, or preferences*. My aim is to develop methods that enable language models to incorporate this feedback consistently, thereby enhancing their reliability.

During my PhD, I had the privilege of being guided by [Derry Wijaya](https://derrywijaya.github.io/web/). I had the enriching experience of collaborating with the talented teams at [Allen AI](https://allenai.org/), [Apple](https://machinelearning.apple.com/) and I often collaborated with [Jacob Andreas](https://www.mit.edu/~jda/) at MIT.



<!-- **Improving Language Models with Feedback**

How can we alter language models to adhere to natural language feedback?

<div class="about-highlight" markdown="1">
- We have devised an automatic [critique generator](https://arxiv.org/abs/2305.08844) called RL4F which is trained with reinforcement learning. RL4F is trained via reinforcement learning and rewarded as long as the generated critiques improved a second model's predictions.

- I have led the curation of a model editing benchmark [DUnE](https://arxiv.org/abs/2311.16087) where edits are natural language sentences. We also showed that retrieval augmented language modeling is superior to specialized editing techniques when edits are natural language phrases.

- Moreover, I have developed [a scheme](https://arxiv.org/abs/2110.07059) that enables growing the number of a classes that an object classifier can recognize using language information about the objects such as labels and descriptions.
</div> -->

<h2 style="margin-top: 1rem;">biography</h2>
{%- include_relative bio.md %}
