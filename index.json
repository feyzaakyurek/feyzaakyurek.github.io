[{"authors":["admin"],"categories":null,"content":"I am a fourth-year Computer Science PhD student at Boston University focusing natural language processing. Before that I received my masters in Statistics from Carnegie Mellon University. I earned my bachelors both in Industrial and Computer Engineering from Koç University, Istanbul. My current research interests are on leveraging natural language for continual learning, collaborative language models, learning from natural language feedback and model editing. In the past, I worked on a diverse set of problems including resource-constrained continual learning, low-resource machine translation and ethics in NLP.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://feyzaakyurek.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a fourth-year Computer Science PhD student at Boston University focusing natural language processing. Before that I received my masters in Statistics from Carnegie Mellon University. I earned my bachelors both in Industrial and Computer Engineering from Koç University, Istanbul.","tags":null,"title":"Afra Feyza Akyürek","type":"authors"},{"authors":["Afra Feyza Akyürek","Sejin Paik","Muhammed Yusuf Kocyigit","Seda Akbiyik","Şerife Leman Runyun","Derry Wijaya"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1667088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667088000,"objectID":"3f28d214ec7a2dcb2977fbac2fdb2b08","permalink":"https://feyzaakyurek.github.io/publication/naacl2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/naacl2022/","section":"publication","summary":"Large language models trained on a mixture of NLP tasks that are converted into a text-to-text format using prompts, can generalize into novel forms of language and handle novel tasks. A large body of work within prompt engineering attempts to understand the effects of input forms and prompts in achieving superior performance. We consider an alternative measure and inquire whether the way in which an input is encoded affects social biases promoted in outputs. In this paper, we study T0, a large-scale multi-task text-to-text language model trained using prompt-based learning. We consider two different forms of semantically equivalent inputs: question-answer format and premise-hypothesis format. We use an existing bias benchmark for the former BBQ and create the first bias benchmark in natural language inference BBNLI with hand-written hypotheses while also converting each benchmark into the other form. The results on two benchmarks suggest that given two different formulations of essentially the same input, T0 conspicuously acts more biased in question answering form, which is seen during training, compared to premise-hypothesis form which is unlike its training examples.","tags":null,"title":"On Measuring Social Biases in Prompt-Based Learning","type":"publication"},{"authors":["Afra Feyza Akyürek","Ekin Akyürek","Derry Wijaya","Jacob Andreas"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1667088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667088000,"objectID":"a5b68cfdeec2d2773e3e46ed10c1f24c","permalink":"https://feyzaakyurek.github.io/publication/iclr2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/iclr2022/","section":"publication","summary":"Few-shot class incremental learning---the problem of updating a trained classifier to discriminate among an expanded set of classes with limited labeled data---is a key challenge for machine learning systems deployed in non-stationary environments. Existing approaches to the problem rely on complex model architectures and training procedures that are difficult to tune and re-use. In this paper, we present an extremely simple approach that enables the use of ordinary logistic regression classifiers for few-shot incremental learning. The key to this approach is a new family of subspace regularization schemes that encourage weight vectors for new classes to lie close to the subspace spanned by the weights of existing classes. When combined with pretrained convolutional feature extractors, logistic regression models trained with subspace regularization outperform specialized, state-of-the-art approaches to few-shot incremental image classification by up to 22% on the *mini*ImageNet dataset. Because of its simplicity, subspace regularization can be straightforwardly extended to incorporate additional background information about the new classes (including class names and descriptions specified in natural language); these further improve accuracy by up to 2%. Our results show that simple geometric regularization of class representations offer an effective tool for continual learning.","tags":null,"title":"Subspace Regularizers for Few-Shot Class Incremental Learning","type":"publication"},{"authors":["Garry Kuwanto*","Afra Feyza Akyürek*","Isidora Chara Tourni*","Siyang Li*","Derry Wijaya"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1664496000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664496000,"objectID":"481dcbec4348b022c82ec4e7d6c160cb","permalink":"https://feyzaakyurek.github.io/publication/acl2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/acl2022/","section":"publication","summary":"We conduct an empirical study of unsupervised neural machine translation (NMT) for truly low resource languages, exploring the case when both parallel training data and compute resource are lacking, reflecting the reality of most of the world's languages and the researchers working on these languages. We propose a simple and scalable method to improve unsupervised NMT, showing how adding comparable data mined using a bilingual dictionary along with modest additional compute resource to train the model can significantly improve its performance. We also demonstrate how the use of the dictionary to code-switch monolingual data to create more comparable data can further improve performance. With this weak supervision, our best method achieves BLEU scores that improve over supervised results for English-Gujarati (+18.88), English-Kazakh (+5.84), and English-Somali (+1.16), showing the promise of weakly-supervised NMT for many low resource languages with modest compute resource in the world. To the best of our knowledge, our work is the first to quantitatively showcase the impact of different modest compute resource in low resource NMT.","tags":null,"title":"Low-Resource Machine Translation Training Curriculum Fit for Low-Resource Languages","type":"publication"},{"authors":["Ekin Akyürek","Afra Feyza Akyürek","Jacob Andreas"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1627603200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627603200,"objectID":"6ab3935df2740463d2dbb24f506112a7","permalink":"https://feyzaakyurek.github.io/publication/iclr2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/iclr2021/","section":"publication","summary":"Flexible neural sequence models outperform grammar and automaton based counterparts on a variety of tasks. However, neural models perform poorly in settings requiring compositional generalization beyond the training data, particularly to rare or unseen subsequences. Past work has found symbolic scaffolding (e.g. grammars or automata) essential in these settings. We present a family of learned data augmentation schemes that support a large category of compositional generalizations without appeal to latent symbolic structure. Our approach to data augmentation has two components: recombination of original training examples via a prototype-based generative model and resampling of generated examples to encourage extrapolation. Training an ordinary neural sequence model on a dataset augmented with recombined and resampled examples significantly improves generalization in two language processing problems, instruction following (SCAN) and morphological analysis (Sigmorphon 2018), where our approach enables learning of new constructions and tenses from as few as eight initial examples.","tags":null,"title":"Learning to Recombine and Resample Data for Compositional Generalization","type":"publication"},{"authors":["Haryo Akbarianto Wibowo","Made Nindyatama Nityasya","Afra Feyza Akyürek","Suci Fitriany","Alham Fikri Aji","Radityo Eko Prasojo","Derry Tanti Wijaya"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1622332800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622332800,"objectID":"a640c57aa109d9454fc0af97a35e1752","permalink":"https://feyzaakyurek.github.io/publication/acl2021findings/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/acl2021findings/","section":"publication","summary":"Indonesian language is heavily riddled with colloquialism whether in written or spoken forms. In this paper, we identify a class of Indonesian colloquial words that have undergone morphological transformations from their standard forms, categorize their word formations, and propose a benchmark dataset of Indonesian Colloquial Lexicons (IndoCollex) consisting of informal words on Twitter expertly annotated with their standard forms and their word formation types/tags. We evaluate several models for character-level transduction to perform morphological word normalization on this testbed to understand their failure cases and provide baselines for future work. As IndoCollex catalogues word formation phenomena that are also present in the non-standard text of other languages, it can also provide an attractive testbed for methods tailored for cross-lingual word normalization and non-standard word formation.","tags":null,"title":"IndoCollex: A Testbed for Morphological Transformation of Indonesian Word Colloquialism","type":"publication"},{"authors":["Afra Feyza Akyürek","Lei Guo","Randa Elanwar","Margrit Betke","Prakash Ishwar","Derry T. Wijaya"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1596067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596067200,"objectID":"76ffa738034a9f7247969cef6c29661a","permalink":"https://feyzaakyurek.github.io/publication/acl2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/acl2020/","section":"publication","summary":"News framing refers to the strategy in which aspects of certain issues are highlighted in the news to promote a particular interpretation. This paper provides an efficient method to automatically determine multiple frames in a given news headline across multiple languages using only basic resources.","tags":null,"title":"Multi-Label and Multilingual News Framing Analysis","type":"publication"},{"authors":["Lei Guo","Yiyan Zhang","Kate Mays","Afra Feyza Akyürek","Derry Wijaya","Margrit Betke"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"203604f10d4c768fed44a8690e57dab1","permalink":"https://feyzaakyurek.github.io/publication/comm_research/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/comm_research/","section":"publication","summary":"Focusing on a polarized issue—U.S. gun violence—this study examines agenda setting as an antecedent of political expression on social media. A state-of-the-art machine-learning model was used to analyze news coverage from 25 media outlets—mainstream and partisan. Those results were paired with a two-wave panel survey conducted during the 2018 U.S. midterm elections. Findings show mainstream media shape public opinion about gun violence, which then stimulates expression about the issue on social media. The study also reveals that partisan media's gun violence coverage has significant cross-cutting effects. Notably, exposure to conservative media will decrease public salience of gun violence, pivot opinion in a more conservative direction, and discourage social media expression; and all of these effects are stronger among liberals.","tags":null,"title":"Agenda Setting, Cross-cutting Effects, and Political Expression on Social Media The Gun Violence Case","type":"publication"},{"authors":["Afra Feyza Akyürek","Ekin Akyürek","Ashwin Kalyan","Peter Clark","Derry Wijaya","Niket Tandon"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"a103aa6c68a21825b20db79d20dbf3f4","permalink":"https://feyzaakyurek.github.io/publication/acl2023/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/acl2023/","section":"publication","summary":"Under review.","tags":null,"title":"Generating Natural Language Feedback with Reinforcement Learning","type":"publication"}]